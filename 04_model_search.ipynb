{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lib.main_func_p1 import timer, path\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from collections import OrderedDict\n",
    "import lib.main_func_p4\n",
    "from lib.main_func_p4 import modelXGBoost_fit_scores\n",
    "\n",
    "\n",
    "#XGBoost library\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "# proteina (uniprot_ID)\n",
    "uniprot_id = 'P22303'\n",
    "path_file = path(uniprot_id)\n",
    "\n",
    "# Archivo de la carpeta TOP SOCORE\n",
    "excel_name = f'{uniprot_id}/P22303_20220621124638_top_scores_XGBClassifier_balanced_accuracy_rf0'\n",
    "resample_factor = int(str.split(excel_name,'_')[-1][2:])\n",
    "resample_mode = 'under_sampling'\n",
    "\n",
    "# Parametros\n",
    "seed = 142854\n",
    "fp_name = 'morgan2_c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load top_scores\n",
    "top_scores = pd.read_excel(f'./top_scores/{excel_name}.xlsx')\n",
    "\n",
    "# Best calibration scores\n",
    "top_socres_len = 15\n",
    "top_scores_top = top_scores.iloc[:top_socres_len]\n",
    "top_scores_top_index_list = top_scores_top.index\n",
    "# top_scores_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved (modelID_407)\n",
      "1/15. modelID_407. AUC_score=(train=0.997, valid=0.965). Time elapsed: 4.1 seconds.\n",
      "2/15. modelID_410. AUC_score=(train=0.996, valid=0.962). Time elapsed: 4.5 seconds.\n",
      "3/15. modelID_448. AUC_score=(train=0.996, valid=0.96). Time elapsed: 4.5 seconds.\n",
      "4/15. modelID_498. AUC_score=(train=0.996, valid=0.961). Time elapsed: 3.7 seconds.\n",
      "5/15. modelID_497. AUC_score=(train=0.996, valid=0.965). Time elapsed: 3.4 seconds.\n"
     ]
    }
   ],
   "source": [
    "reload(lib.main_func_p4)\n",
    "from lib.main_func_p4 import modelXGBoost_fit_scores\n",
    "\n",
    "# Load train and validation datasets\n",
    "df_train = pd.read_pickle(f'{path_file}_dataset_train')\n",
    "df_valid = pd.read_pickle(f'{path_file}_dataset_valid')\n",
    "\n",
    "new_row_list = list()\n",
    "results_ROF_list_train = list()\n",
    "results_ROF_list_valid = list()\n",
    "df_list = list()\n",
    "plots_name_list = list()\n",
    "\n",
    "for i, params_dict in enumerate(top_scores.params_dict.iloc[0:top_socres_len]):\n",
    "    eval_metric = ['error', 'auc']\n",
    "    tick = timer()\n",
    "    params_dict = dict(eval(params_dict))\n",
    "    default_params_xgb = {'booster': 'gbtree', 'tree_method': 'gpu_hist',\n",
    "                          'objective':'binary:logistic', 'grow_policy': 'depthwise',\n",
    "                          'eval_metric': eval_metric, 'early_stopping_rounds':10}\n",
    "    params_dict.update(default_params_xgb)\n",
    "\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(**params_dict)\n",
    "\n",
    "    # Train model and evaluating scores (train / validation)\n",
    "    xgb_clf, scores_train, scores_valid = modelXGBoost_fit_scores(xgb_clf, fp_name, df_train, df_valid,\n",
    "                                                                  resample_factor=resample_factor,\n",
    "                                                                  resample_mode=resample_mode)\n",
    "\n",
    "    if i == 0:\n",
    "        xgb_clf.save_model(f'./models/{uniprot_id}_model.ubj')\n",
    "        print(f'Best model saved ({top_scores.model.iloc[i]})')\n",
    "\n",
    "    # ROF results\n",
    "    results_ROF_list_train.append(scores_train[7])\n",
    "    results_ROF_list_valid.append(scores_valid[7])\n",
    "\n",
    "    # save pred and pred_prob of train set\n",
    "    df = df_train[['activity', 'prediction', 'prediction_prob']].copy()\n",
    "    df_list.append(df)\n",
    "\n",
    "    plots_name_list.append(top_scores.model.iloc[i])\n",
    "    print(f'{i+1}/{top_socres_len}. {top_scores.model.iloc[i]}. AUC_score=(train={scores_train[0]},'\n",
    "          f' valid={scores_valid[0]}). Time elapsed: {timer(tick)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ROC curve - best scores\n",
    "reload(lib.main_func_p4)\n",
    "from lib.main_func_p4 import plot_ROC_curve\n",
    "results_ROF_train_list_top = list()\n",
    "results_ROF_valid_list_top = list()\n",
    "ROC_plots_name_top_name = list()\n",
    "for i in top_scores_top_index_list:\n",
    "    results_ROF_train_list_top.append(results_ROF_list_train[i])\n",
    "    results_ROF_valid_list_top.append(results_ROF_list_valid[i])\n",
    "    ROC_plots_name_top_name.append(plots_name_list[i])\n",
    "\n",
    "model_name = f'XGBoost_Clf Train set (TOP)'\n",
    "plot_ROC_curve(results_ROF_train_list_top, ROC_plots_name_top_name, model_name,\n",
    "               path_file=path_file, name_mod=\"train_Top_score\", save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_name = f'XGBoost_Clf validation set (TOP)'\n",
    "plot_ROC_curve(results_ROF_valid_list_top, ROC_plots_name_top_name, model_name,\n",
    "               path_file=path_file, name_mod=\"validation_Top_score\", save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calibration curve - best scores (10)\n",
    "reload(lib.main_func_p4)\n",
    "from lib.main_func_p4 import plot_calibration_curve\n",
    "df_list_top = list()\n",
    "df_list_top_name = list()\n",
    "model_name = f'XGBoost_Clf train set (TOP)'\n",
    "# Only graph top 5\n",
    "for i in top_scores_top_index_list:\n",
    "    df_list_top.append(df_list[i])\n",
    "    df_list_top_name.append((plots_name_list[i]))\n",
    "plot_calibration_curve(df_list_top[:5], df_list_top_name[:5], model_name,\n",
    "                       path_file=path_file, name_mod=\"train_Top_score\", save_fig=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}