{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "\"\"\" Versión 'notebook' del scrip .py \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from collections import OrderedDict\n",
    "from importlib import reload\n",
    "\n",
    "from lib.main_func_p1 import path\n",
    "from lib.main_func_p3 import calculate_onefp\n",
    "from lib.main_func_p4 import model_clf\n",
    "from lib.main_func_p4 import modelXGBoost_fit_scores\n",
    "from lib.main_func_p4 import resampling_set\n",
    "from lib.main_func_p4 import plot_ROC_curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def imgs_to_pdf(img_dir, save_dir=None, save_name=None, res=400):\n",
    "    from img2pdf import convert\n",
    "    list_images = list()\n",
    "    for file in os.listdir(img_dir):\n",
    "        try:\n",
    "            checker = file.rsplit('_')[1]\n",
    "        except IndexError:\n",
    "            checker = ''\n",
    "        if checker == 'summary':\n",
    "            list_images.append(f'{img_dir}/{file}')\n",
    "    with open(f'{save_dir}/{save_name}', 'wb') as pdf:\n",
    "        pdf.write(convert(list_images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "#####################################\n",
    "# proteina (uniprot_ID)\n",
    "uniprot_id = 'P56817' # Solmante es necesario cambiar la proteina\n",
    "\n",
    "# Parametros\n",
    "path_file = path(uniprot_id)\n",
    "seed = 142854\n",
    "fp_name = 'morgan2_c'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P56817 - f1_weighted - 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [66]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     33\u001B[0m xgbc_tuned \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mXGBClassifier(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams_dict)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Train model and evaluating scores (train / validation)\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m xgbc_tuned, scores_train, scores_valid \u001B[38;5;241m=\u001B[39m \u001B[43mmodelXGBoost_fit_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxgbc_tuned\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mresample_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mresample_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m xgbc_tuned\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muniprot_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_model.ubj\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     39\u001B[0m xgbc_tuned, df_results_model_tuned, results_ROC_fp \u001B[38;5;241m=\u001B[39m model_clf(xgbc_tuned, fp_name, uniprot_id, seed\u001B[38;5;241m=\u001B[39mseed,\n\u001B[0;32m     40\u001B[0m                                                                save_log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\My Drive\\Python\\ML_for_DD\\lib\\main_func_p4.py:219\u001B[0m, in \u001B[0;36mmodelXGBoost_fit_scores\u001B[1;34m(xgb_clf, fp_name, df_set, df_valid, resample_factor, resample_mode, verbose)\u001B[0m\n\u001B[0;32m    217\u001B[0m pred_train \u001B[38;5;241m=\u001B[39m xgb_clf\u001B[38;5;241m.\u001B[39mpredict(X_set\u001B[38;5;241m.\u001B[39mto_list())\n\u001B[0;32m    218\u001B[0m df_set[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pred_train\n\u001B[1;32m--> 219\u001B[0m pred_prob_train \u001B[38;5;241m=\u001B[39m \u001B[43mxgb_clf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    220\u001B[0m df_set[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction_prob\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pred_prob_train\n\u001B[0;32m    221\u001B[0m scores_train \u001B[38;5;241m=\u001B[39m model_metrics_score(y_set, pred_train, pred_prob_train)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\sklearn.py:1512\u001B[0m, in \u001B[0;36mXGBClassifier.predict_proba\u001B[1;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti:softmax\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1505\u001B[0m     \u001B[38;5;66;03m# We need to run a Python implementation of softmax for it.  Just ask user to\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m     \u001B[38;5;66;03m# use softprob since XGBoost's implementation has mitigation for floating\u001B[39;00m\n\u001B[0;32m   1507\u001B[0m     \u001B[38;5;66;03m# point overflow.  No need to reinvent the wheel.\u001B[39;00m\n\u001B[0;32m   1508\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1509\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti:softmax doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt support `predict_proba`.  \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1510\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSwitch to `multi:softproba` instead\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1511\u001B[0m     )\n\u001B[1;32m-> 1512\u001B[0m class_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1513\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1514\u001B[0m \u001B[43m    \u001B[49m\u001B[43mntree_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mntree_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1515\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1517\u001B[0m \u001B[43m    \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\n\u001B[0;32m   1518\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1519\u001B[0m \u001B[38;5;66;03m# If model is loaded from a raw booster there's no `n_classes_`\u001B[39;00m\n\u001B[0;32m   1520\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _cls_predict_proba(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_classes_\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m), class_probs, np\u001B[38;5;241m.\u001B[39mvstack)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\sklearn.py:1065\u001B[0m, in \u001B[0;36mXGBModel.predict\u001B[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m   1061\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   1062\u001B[0m         \u001B[38;5;66;03m# coo, csc, dt\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m-> 1065\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mDMatrix\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1066\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1067\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnthread\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_categorical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menable_categorical\u001B[49m\n\u001B[0;32m   1070\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_booster()\u001B[38;5;241m.\u001B[39mpredict(\n\u001B[0;32m   1072\u001B[0m     data\u001B[38;5;241m=\u001B[39mtest,\n\u001B[0;32m   1073\u001B[0m     iteration_range\u001B[38;5;241m=\u001B[39miteration_range,\n\u001B[0;32m   1074\u001B[0m     output_margin\u001B[38;5;241m=\u001B[39moutput_margin,\n\u001B[0;32m   1075\u001B[0m     validate_features\u001B[38;5;241m=\u001B[39mvalidate_features,\n\u001B[0;32m   1076\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\core.py:532\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    531\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 532\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\core.py:643\u001B[0m, in \u001B[0;36mDMatrix.__init__\u001B[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001B[0m\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 643\u001B[0m handle, feature_names, feature_types \u001B[38;5;241m=\u001B[39m \u001B[43mdispatch_data_backend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    644\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    645\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnthread\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_categorical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_categorical\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m handle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\data.py:892\u001B[0m, in \u001B[0;36mdispatch_data_backend\u001B[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001B[0m\n\u001B[0;32m    890\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_uri(data, missing, feature_names, feature_types)\n\u001B[0;32m    891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_list(data):\n\u001B[1;32m--> 892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_from_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_tuple(data):\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML_for_DD\\lib\\site-packages\\xgboost\\data.py:823\u001B[0m, in \u001B[0;36m_from_list\u001B[1;34m(data, missing, n_threads, feature_names, feature_types)\u001B[0m\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_from_list\u001B[39m(\n\u001B[0;32m    816\u001B[0m     data,\n\u001B[0;32m    817\u001B[0m     missing,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    820\u001B[0m     feature_types: Optional[List[\u001B[38;5;28mstr\u001B[39m]],\n\u001B[0;32m    821\u001B[0m ):\n\u001B[0;32m    822\u001B[0m     array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(data)\n\u001B[1;32m--> 823\u001B[0m     \u001B[43m_check_data_shape\u001B[49m(data)\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_numpy_array(array, missing, n_threads, feature_names, feature_types)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "all_type=False\n",
    "save=True\n",
    "\n",
    "list_excelfiles_to_process = []\n",
    "for file in os.listdir(f'./top_scores/{uniprot_id}'):\n",
    "    list_excelfiles_to_process.append(file)\n",
    "\n",
    "ADME_df = pd.read_csv(f'{path_file}_02_ligands_smiles_ADME_lipinski.csv')\n",
    "for excel_file in list_excelfiles_to_process:\n",
    "    # Load top_scores excel file\n",
    "    top_scores = pd.read_excel(f'./top_scores/{uniprot_id}/{excel_file}')\n",
    "    score_metric = '_'.join(str.split(excel_file,'_')[5:-1])\n",
    "    resample_factor = int(str.split(excel_file,'_')[-1][2:][:-5])\n",
    "    resample_mode = 'under_sampling'\n",
    "    model_name = f'XGBoost_Clf'\n",
    "    # now = datetime.strftime(datetime.now(), '%Y%m%d%H%M%S')\n",
    "    img_name = f'{score_metric}_{resample_factor}.png'\n",
    "    print(f'{uniprot_id} - {score_metric} - {resample_factor}')\n",
    "\n",
    "    # Load train and validation datasets\n",
    "    df_train = pd.read_pickle(f'{path_file}_dataset_train')\n",
    "    df_valid = pd.read_pickle(f'{path_file}_dataset_valid')\n",
    "    X_valid, y_valid = df_valid[fp_name].tolist(), df_valid['activity'].tolist()\n",
    "\n",
    "    eval_metric = ['error', 'auc']\n",
    "    params_dict = dict(eval(top_scores.params_dict[0]))\n",
    "    default_params_xgb = {'booster': 'gbtree', 'tree_method': 'gpu_hist',\n",
    "                              'objective':'binary:logistic', 'grow_policy': 'depthwise',\n",
    "                              'eval_metric': eval_metric, 'early_stopping_rounds':10}\n",
    "    params_dict.update(default_params_xgb)\n",
    "\n",
    "    # train and save the 'best' model\n",
    "    xgbc_tuned = xgb.XGBClassifier(**params_dict)\n",
    "    # Train model and evaluating scores (train / validation)\n",
    "    xgbc_tuned, scores_train, scores_valid = modelXGBoost_fit_scores(xgbc_tuned, fp_name, df_train, df_valid,\n",
    "                                                                  resample_factor=resample_factor,\n",
    "                                                                  resample_mode=resample_mode, verbose=False)\n",
    "    xgbc_tuned.save_model(f'./models/{uniprot_id}_model.ubj')\n",
    "    xgbc_tuned, df_results_model_tuned, results_ROC_fp = model_clf(xgbc_tuned, fp_name, uniprot_id, seed=seed,\n",
    "                                                                   save_log=True, verbose=False)\n",
    "\n",
    "    # Calcular probabilidades del conjunto de datos externo\n",
    "    pred_valid = xgbc_tuned.predict(X_valid)\n",
    "    df_valid['prediction'] = pred_valid\n",
    "\n",
    "    prediction_prob_valid = np.array(xgbc_tuned.predict_proba(X_valid)[:,1])\n",
    "    df_valid['prediction_prob'] = prediction_prob_valid\n",
    "\n",
    "    #metricas\n",
    "    fpr_valid, tpr_valid, _ = roc_curve(y_valid, prediction_prob_valid)\n",
    "    auc_score_unseen = auc(fpr_valid, tpr_valid)\n",
    "    metrics_ROC_valid = (fpr_valid, tpr_valid, auc_score_unseen)\n",
    "    metrics_ROC = results_ROC_fp.copy()\n",
    "    metrics_ROC.extend([metrics_ROC_valid])\n",
    "    metrics_ROC_name = ['train(internal)', 'test(internal)', 'validation(external)']\n",
    "\n",
    "    # Decoys\n",
    "    decoy_samples = min(list(df_valid.activity.value_counts()))\n",
    "    df_decoys = pd.DataFrame(columns=['smiles'])\n",
    "    list_d = list()\n",
    "    decoys_len = int(decoy_samples)\n",
    "    with open(f'data/_decoys/{uniprot_id}_all_smiles.ism', 'rb') as f:\n",
    "        decoys_line = f.readlines()\n",
    "        for line in decoys_line[1:]: #la primera linea es header\n",
    "            line = line.decode('UTF-8').split()\n",
    "            list_d.append(line)\n",
    "    df_decoys = pd.DataFrame(list_d, columns=['smiles', 'id'])\n",
    "    df_decoys = df_decoys.sample(n=decoys_len, ignore_index=True)\n",
    "    calculate_onefp(df_decoys, fp_name)\n",
    "    df_decoys.drop_duplicates(subset=['smiles'], inplace=True)\n",
    "    df_decoys.reset_index(inplace=True, drop=True)\n",
    "    df_decoys = df_decoys.drop(['mol'], axis=1)\n",
    "    df_decoys = df_decoys.drop(['smiles'], axis=1)\n",
    "    df_decoys['type'] = 'decoy'\n",
    "    df_decoys = df_decoys[['type', fp_name]]\n",
    "    x_decoy = df_decoys[fp_name].tolist()\n",
    "    pred_decoy = xgbc_tuned.predict(x_decoy)\n",
    "    prediction_prob = xgbc_tuned.predict_proba(x_decoy)[:,1]\n",
    "    prediction_prob = np.array(prediction_prob)\n",
    "    df_decoys['activity'] = 0.0\n",
    "    df_decoys['prediction'] = pred_decoy\n",
    "    df_decoys['prediction_prob'] = prediction_prob\n",
    "\n",
    "    # Resample\n",
    "    df_valid_rsmpl = resampling_set(df_valid, mode='under_sampling', ratio=1)\n",
    "    df_valid_rsmpl['type'] = 'valid_inactive'\n",
    "    df_valid_rsmpl.loc[df_valid_rsmpl[df_valid_rsmpl.activity == 1.0].index, 'type'] = 'valid_active'\n",
    "    df_valid_rsmpl.reset_index(drop=True, inplace=True)\n",
    "    df_valid_rsmpl = df_valid_rsmpl[['type', fp_name, 'activity', 'prediction', 'prediction_prob']]\n",
    "    X_valid_rsmpl, y_valid_rsmpl = df_valid_rsmpl[fp_name].tolist(), df_valid_rsmpl['activity'].tolist()\n",
    "\n",
    "    # Datos Calibración\n",
    "    df_internal = pd.read_pickle(f'{path_file}_dataset_train')\n",
    "    X_test, y_test = df_internal[fp_name].tolist(), df_internal['activity'].tolist()\n",
    "    pred_test = xgbc_tuned.predict(X_test)\n",
    "    df_internal['prediction'] = pred_test\n",
    "\n",
    "    prediction_prob_test = np.array(xgbc_tuned.predict_proba(X_test)[:,1])\n",
    "    df_internal['prediction_prob'] = prediction_prob_test\n",
    "\n",
    "    sns.set_theme()\n",
    "    title_size, normal_size = 16, 14\n",
    "    grid_rows, grid_columns = 6, 4\n",
    "    figure, axes = plt.subplots(grid_rows, grid_columns, figsize=(20, 30))\n",
    "    gs = GridSpec(grid_rows, grid_columns, figure=figure)\n",
    "    gs_2 = GridSpec(grid_rows, grid_columns, figure=figure, width_ratios=[1.5, 1.5, 1, 0])\n",
    "    figure.suptitle(f'Protein: {uniprot_id} - model: {model_name} - score: {score_metric} - resample_factor: {resample_factor} ', size=20)\n",
    "    for i in range(grid_rows):\n",
    "        for j in range(grid_columns):\n",
    "            axes[i, j].remove()\n",
    "    axes[0,0] = figure.add_subplot(gs[:2, 0])\n",
    "    axes[0,1] = figure.add_subplot(gs[:2, 1:3])\n",
    "    axes[2,0] = figure.add_subplot(gs[2:3, 0:1])\n",
    "    axes[3,0] = figure.add_subplot(gs[3:4, 0:1])\n",
    "    axes[2,1] = figure.add_subplot(gs[2:4, 1:3])\n",
    "    axes[4,0] = figure.add_subplot(gs_2[4:5, 0:1])\n",
    "    axes[4,2] = figure.add_subplot(gs_2[4:5, 1:2])\n",
    "    axes[4,3] = figure.add_subplot(gs_2[4:5, 2:3])\n",
    "\n",
    "    # 1. Plot  count active /inactive\n",
    "    if all_type:\n",
    "        sns.countplot(ax=axes[0,0], x='activity_type', data=ADME_df, order=['Inactive', 'Intermediate', 'Active'])\n",
    "    else:\n",
    "        sns.countplot(ax=axes[0,0], x='activity_type', data=ADME_df, order=['Inactive', 'Active'], palette=['tab:orange',\"tab:blue\"])\n",
    "    axes[0,0].set_title(f'Total: {len(ADME_df)}',fontsize=title_size)\n",
    "    axes[0,0].bar_label(container=axes[0,0].containers[0], fmt='%g', fontsize=normal_size)\n",
    "    axes[0,0].set_xlabel('activity type', size=normal_size)\n",
    "    axes[0,0].set_ylabel('count', size=normal_size)\n",
    "    axes[0,0].tick_params(labelsize=normal_size)\n",
    "    # -------------------------------\n",
    "\n",
    "    # 2. Plot  ROC curve\n",
    "    cmap = cm.get_cmap('Blues')\n",
    "    colors = [cmap(i) for i in np.linspace(0.3, 1.0, len(metrics_ROC))]\n",
    "    for i, metrics in enumerate(metrics_ROC):\n",
    "        fpr, tpr, roc_auc = metrics[0], metrics[1], metrics[2]\n",
    "        name = metrics_ROC_name[i]\n",
    "        axes[0,1].plot(fpr, tpr, lw=1, color=colors[i], label='AUC_{} = {:.3f}'.format(name, roc_auc))\n",
    "\n",
    "    axes[0,1].plot([0, 1], [0, 1], linestyle='--', label='Random', lw=2, color=\"black\")  # Random curve\n",
    "    axes[0,1].set_xlabel('False positive rate', size=normal_size)\n",
    "    axes[0,1].set_ylabel('True positive rate', size=normal_size)\n",
    "    axes[0,1].set_title(model_name + ' ROC curve', size=title_size)\n",
    "    axes[0,1].tick_params(labelsize=normal_size)\n",
    "    axes[0,1].legend(fontsize=normal_size, loc=(1.04, 0))\n",
    "\n",
    "    # 3. Calibration curve\n",
    "    df_plots_list = [df_internal, df_valid]\n",
    "    list_plots_name = ['model_train', 'model_validation']\n",
    "    axes[2,1].plot([0, 1], [0, 1], linestyle='--', label='perfectly_calibrated')\n",
    "\n",
    "    for i, df in enumerate(df_plots_list):\n",
    "        clf_score = round(brier_score_loss(df['activity'], df['prediction_prob'], pos_label=1), 3)\n",
    "        fop, mpv = calibration_curve(df['activity'], df['prediction_prob'], n_bins=5)\n",
    "        name = list_plots_name[i]\n",
    "        # plot model reliability\n",
    "        axes[2,1].plot(mpv, fop, marker='.', label=f'{name}: {clf_score}')\n",
    "\n",
    "    axes[2,1].set_xlabel('Mean predicted probability', size=normal_size)\n",
    "    axes[2,1].set_ylabel('Fraction of positives', size=normal_size)\n",
    "    axes[2,1].set_title(model_name + ' calibration curve', size=title_size)\n",
    "    axes[2,1].tick_params(labelsize=normal_size)\n",
    "    axes[2,1].legend(fontsize=normal_size, loc=(1.04, 0))\n",
    "\n",
    "    # 4 Confusion Matrix'\n",
    "    plt.rc('font', size=20)\n",
    "    disp1 = ConfusionMatrixDisplay.from_estimator(xgbc_tuned, X_valid_rsmpl, y_valid_rsmpl,\n",
    "                                                  cmap=plt.cm.Blues, normalize=None,\n",
    "                                                  colorbar=False, ax=axes[2,0])\n",
    "    axes[2,0].grid(False)\n",
    "    axes[2,0].tick_params(labelsize=normal_size)\n",
    "    axes[2,0].set_xlabel('Predicted label', size=normal_size)\n",
    "    axes[2,0].set_ylabel('True label', size=normal_size)\n",
    "    axes[2,0].set_title('Confusion Matrix', size=title_size)\n",
    "\n",
    "    disp2 = ConfusionMatrixDisplay.from_estimator(xgbc_tuned, X_valid_rsmpl, y_valid_rsmpl,\n",
    "                                                  cmap=plt.cm.Blues, normalize='true',\n",
    "                                                  colorbar=False, ax=axes[3,0])\n",
    "    axes[3,0].grid(False)\n",
    "    axes[3,0].tick_params(labelsize=normal_size)\n",
    "    axes[3,0].set_xlabel('Predicted label', size=normal_size)\n",
    "    axes[3,0].set_ylabel('True label', size=normal_size)\n",
    "    axes[3,0].set_title('Confusion Matrix (nomr)', size=title_size)\n",
    "    plt.rc('font', size=8)\n",
    "\n",
    "    # 5. Probability prediction Histogram\n",
    "    # Unir decoys + resample\n",
    "    df_inactive = df_valid_rsmpl[df_valid_rsmpl['type'] == 'valid_inactive']\n",
    "    sns.histplot(ax=axes[4,0], data=df_inactive, x=\"prediction_prob\", bins=20, stat='percent', element=\"step\", color='tab:orange')\n",
    "    axes[4,0].tick_params(labelsize=normal_size)\n",
    "    axes[4,0].set_xlabel('Predicted probability', size=normal_size)\n",
    "    axes[4,0].set_ylabel('Percent', size=normal_size)\n",
    "    axes[4,0].set_title('Inactive Histogram', size=title_size)\n",
    "\n",
    "    df_active = df_valid_rsmpl[df_valid_rsmpl['type'] == 'valid_active']\n",
    "    sns.histplot(ax=axes[4,2], data=df_active, x=\"prediction_prob\", bins=20, stat='percent', element=\"step\", color='tab:blue')\n",
    "    axes[4,2].tick_params(labelsize=normal_size)\n",
    "    axes[4,2].set_xlabel('Predicted probability', size=normal_size)\n",
    "    axes[4,2].set_ylabel('Percent', size=normal_size)\n",
    "    axes[4,2].set_title('Active Histogram', size=title_size)\n",
    "\n",
    "    sns.histplot(ax=axes[4,3], data=df_decoys, x=\"prediction_prob\", bins=20, stat='percent', element=\"step\", color='tab:green')\n",
    "    axes[4,3].tick_params(labelsize=normal_size)\n",
    "    axes[4,3].set_xlabel('Predicted probability', size=normal_size)\n",
    "    axes[4,3].set_ylabel('Percent', size=normal_size)\n",
    "    axes[4,3].set_title('Decoys Histogram', size=title_size)\n",
    "\n",
    "    # set the spacing between subplots\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=0.95, wspace=0.2, hspace=0.3)\n",
    "    plt.savefig(f'{path_file}_summary_{img_name}', bbox_inches='tight')\n",
    "    print(f'>> {uniprot_id}_summary_{img_name}: SAVED')\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "img_dir = save_dir = f'./data/{uniprot_id}'\n",
    "save_name = f'SUMMARY_{uniprot_id}.pdf'\n",
    "imgs_to_pdf(img_dir, save_dir, save_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}